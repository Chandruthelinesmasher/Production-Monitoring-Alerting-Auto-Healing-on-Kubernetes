name: SRE AKS CI/CD Pipeline

on:
  push:
    branches: ["main"]
  workflow_dispatch:

permissions:
  contents: read

env:
  TF_VERSION: "1.6.6"

  # App
  IMAGE_NAME: k8s-sre-monitoring-app

  # Infra
  LOCATION: eastus2
  RESOURCE_GROUP: rg-sre-monitoring-dev

  # Terraform Backend
  BACKEND_RESOURCE_GROUP: rg-terraform-state
  BACKEND_STORAGE_ACCOUNT: tfstatesremonitoring
  BACKEND_CONTAINER: tfstate
  BACKEND_KEY: sre-monitoring-dev.tfstate

jobs:
# ==========================================================
# TERRAFORM â€“ INFRASTRUCTURE
# ==========================================================
  terraform:
    name: Terraform Infra
    runs-on: ubuntu-latest

    outputs:
      acr_login_server: ${{ steps.tfout.outputs.acr_login_server }}
      acr_name: ${{ steps.tfout.outputs.acr_name }}
      aks_name: ${{ steps.tfout.outputs.aks_name }}
      resource_group: ${{ steps.tfout.outputs.resource_group }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      # -----------------------------
      # Azure Login (Secret Method)
      # -----------------------------
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      # -----------------------------
      # Export ARM vars for Terraform
      # -----------------------------
      - name: Export ARM variables
        run: |
          CREDS='${{ secrets.AZURE_CREDENTIALS }}'
          echo "ARM_CLIENT_ID=$(echo $CREDS | jq -r .clientId)" >> $GITHUB_ENV
          echo "ARM_CLIENT_SECRET=$(echo $CREDS | jq -r .clientSecret)" >> $GITHUB_ENV
          echo "ARM_TENANT_ID=$(echo $CREDS | jq -r .tenantId)" >> $GITHUB_ENV
          echo "ARM_SUBSCRIPTION_ID=$(echo $CREDS | jq -r .subscriptionId)" >> $GITHUB_ENV

      # -----------------------------
      # Setup Terraform
      # -----------------------------
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      # -----------------------------
      # Backend Storage (Idempotent)
      # -----------------------------
      - name: Setup Terraform Backend
        run: |
          az group create \
            --name $BACKEND_RESOURCE_GROUP \
            --location $LOCATION \
            --tags purpose=terraform-state || true

          if ! az storage account show \
            --name $BACKEND_STORAGE_ACCOUNT \
            --resource-group $BACKEND_RESOURCE_GROUP &>/dev/null; then
            az storage account create \
              --name $BACKEND_STORAGE_ACCOUNT \
              --resource-group $BACKEND_RESOURCE_GROUP \
              --location $LOCATION \
              --sku Standard_LRS \
              --https-only true
          fi

          ACCOUNT_KEY=$(az storage account keys list \
            --resource-group $BACKEND_RESOURCE_GROUP \
            --account-name $BACKEND_STORAGE_ACCOUNT \
            --query '[0].value' -o tsv)

          az storage container create \
            --name $BACKEND_CONTAINER \
            --account-name $BACKEND_STORAGE_ACCOUNT \
            --account-key $ACCOUNT_KEY || true

      # -----------------------------
      # Terraform Init
      # -----------------------------
      - name: Terraform Init
        run: |
          cd terraform
          terraform init -upgrade \
            -backend-config="resource_group_name=$BACKEND_RESOURCE_GROUP" \
            -backend-config="storage_account_name=$BACKEND_STORAGE_ACCOUNT" \
            -backend-config="container_name=$BACKEND_CONTAINER" \
            -backend-config="key=$BACKEND_KEY"

      - name: Terraform Validate
        run: |
          cd terraform
          terraform validate

      - name: Terraform Plan
        run: |
          cd terraform
          terraform plan \
            -var="location=$LOCATION" \
            -var="resource_group_name=$RESOURCE_GROUP" \
            -var="environment=dev" \
            -out=tfplan

      - name: Terraform Apply
        run: |
          cd terraform
          terraform apply -auto-approve tfplan

      # -----------------------------
      # ACR Integration with AKS
      # -----------------------------
      - name: Configure ACR Pull Permission for AKS
        run: |
          echo "=========================================="
          echo "Configuring ACR integration with AKS..."
          echo "=========================================="
          
          AKS_NAME=$(cd terraform && terraform output -raw aks_cluster_name)
          ACR_NAME=$(cd terraform && terraform output -raw acr_name)
          
          echo "AKS Cluster: $AKS_NAME"
          echo "ACR Name: $ACR_NAME"
          echo ""
          
          # Method 1: Use AKS attach-acr (Recommended - Idempotent)
          echo "ðŸ”— Attaching ACR to AKS cluster..."
          if az aks update \
            --resource-group $RESOURCE_GROUP \
            --name $AKS_NAME \
            --attach-acr $ACR_NAME \
            --no-wait 2>&1 | tee /tmp/attach-acr.log; then
            echo "âœ… ACR attach command executed successfully"
          else
            echo "âš ï¸  ACR attach failed or already attached, trying manual assignment..."
          fi
          
          # Wait for the update to propagate
          echo ""
          echo "â³ Waiting 45 seconds for ACR integration to propagate..."
          sleep 45
          
          # Method 2: Manual role assignment (Fallback)
          echo ""
          echo "ðŸ” Verifying role assignment..."
          
          AKS_KUBELET_ID=$(az aks show \
            --resource-group $RESOURCE_GROUP \
            --name $AKS_NAME \
            --query identityProfile.kubeletidentity.objectId -o tsv)
          
          ACR_ID=$(az acr show \
            --name $ACR_NAME \
            --resource-group $RESOURCE_GROUP \
            --query id -o tsv)
          
          echo "Kubelet Identity: $AKS_KUBELET_ID"
          echo "ACR Resource ID: $ACR_ID"
          echo ""
          
          # Check if role already exists
          EXISTING_ROLE=$(az role assignment list \
            --assignee $AKS_KUBELET_ID \
            --scope $ACR_ID \
            --query "[?roleDefinitionName=='AcrPull'].roleDefinitionName" -o tsv)
          
          if [ -z "$EXISTING_ROLE" ]; then
            echo "ðŸ“ Creating AcrPull role assignment..."
            az role assignment create \
              --assignee $AKS_KUBELET_ID \
              --role AcrPull \
              --scope $ACR_ID
            echo "âœ… Role assignment created"
            
            # Wait for role propagation
            echo "â³ Waiting 30 seconds for role propagation..."
            sleep 30
          else
            echo "âœ… AcrPull role already assigned"
          fi
          
          # Final verification
          echo ""
          echo "=========================================="
          echo "Final Role Assignment Status:"
          echo "=========================================="
          az role assignment list \
            --assignee $AKS_KUBELET_ID \
            --scope $ACR_ID \
            --query "[?roleDefinitionName=='AcrPull'].{Role:roleDefinitionName,Scope:scope}" -o table
          
          echo ""
          echo "âœ… ACR integration configuration complete!"

      - name: Export Terraform Outputs
        id: tfout
        run: |
          cd terraform
          echo "acr_login_server=$(terraform output -raw acr_login_server)" >> $GITHUB_OUTPUT
          echo "acr_name=$(terraform output -raw acr_name)" >> $GITHUB_OUTPUT
          echo "aks_name=$(terraform output -raw aks_cluster_name)" >> $GITHUB_OUTPUT
          echo "resource_group=$(terraform output -raw resource_group_name)" >> $GITHUB_OUTPUT

# ==========================================================
# BUILD & PUSH IMAGE
# ==========================================================
  build-and-push:
    name: Build & Push Docker Image
    needs: terraform
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Login to ACR
        run: az acr login --name ${{ needs.terraform.outputs.acr_name }}

      - name: Verify app directory exists
        run: |
          if [ ! -d "app" ]; then
            echo "Error: app directory not found!"
            echo "Repository structure:"
            ls -la
            exit 1
          fi
          echo "App directory contents:"
          ls -la app/

      - name: Build Image
        run: |
          cd app
          docker build \
            -t ${{ needs.terraform.outputs.acr_login_server }}/${{ env.IMAGE_NAME }}:latest \
            -t ${{ needs.terraform.outputs.acr_login_server }}/${{ env.IMAGE_NAME }}:${{ github.sha }} \
            .

      - name: Push Images
        run: |
          docker push ${{ needs.terraform.outputs.acr_login_server }}/${{ env.IMAGE_NAME }}:latest
          docker push ${{ needs.terraform.outputs.acr_login_server }}/${{ env.IMAGE_NAME }}:${{ github.sha }}

# ==========================================================
# DEPLOY APP + MONITORING
# ==========================================================
  deploy:
    name: Deploy App & Monitoring
    needs: [terraform, build-and-push]
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get AKS Credentials
        run: |
          az aks get-credentials \
            --resource-group ${{ needs.terraform.outputs.resource_group }} \
            --name ${{ needs.terraform.outputs.aks_name }} \
            --overwrite-existing

      - name: Create Namespaces
        run: |
          kubectl create namespace app --dry-run=client -o yaml | kubectl apply -f -
          kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

      - name: Deploy Monitoring Stack (First)
        run: |
          echo "Installing Prometheus Operator and monitoring stack..."
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          
          helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
            -n monitoring \
            --set grafana.adminPassword=admin123 \
            --wait \
            --timeout 10m
          
          echo "Waiting for Prometheus Operator CRDs to be ready..."
          kubectl wait --for condition=established --timeout=300s \
            crd/servicemonitors.monitoring.coreos.com || echo "ServiceMonitor CRD check timed out"

      - name: Deploy Application
        run: |
          echo "Deploying application resources..."
          sed -i "s|IMAGE_PLACEHOLDER|${{ needs.terraform.outputs.acr_login_server }}/${{ env.IMAGE_NAME }}:latest|g" k8s/app/deployment.yaml
          kubectl apply -f k8s/app -n app
          
          echo "Application deployed successfully"

      - name: Deploy ServiceMonitor
        run: |
          echo "Deploying ServiceMonitor for metrics scraping..."
          
          # Check if ServiceMonitor CRD exists
          if kubectl get crd servicemonitors.monitoring.coreos.com &>/dev/null; then
            kubectl apply -f k8s/monitoring/servicemonitor.yaml
            echo "âœ… ServiceMonitor deployed successfully"
          else
            echo "âš ï¸  ServiceMonitor CRD not found. Skipping ServiceMonitor deployment."
            echo "This usually means Prometheus Operator is not fully installed yet."
          fi

      - name: Verify Deployment
        run: |
          echo "Waiting for pods to be ready..."
          kubectl wait --for=condition=ready pod -l app=sre-app -n app --timeout=300s || {
            echo "âš ï¸  Pods failed to become ready. Checking pod status..."
            kubectl get pods -n app
            echo ""
            echo "Pod Events:"
            kubectl describe pods -l app=sre-app -n app | grep -A 20 Events:
            exit 1
          }
          
          echo ""
          echo "=========================================="
          echo "=== APPLICATION PODS ==="
          echo "=========================================="
          kubectl get pods -n app -o wide
          
          echo ""
          echo "=========================================="
          echo "=== MONITORING PODS ==="
          echo "=========================================="
          kubectl get pods -n monitoring
          
          echo ""
          echo "=========================================="
          echo "=== APPLICATION SERVICES ==="
          echo "=========================================="
          kubectl get svc -n app
          
          echo ""
          echo "=========================================="
          echo "=== MONITORING SERVICES ==="
          echo "=========================================="
          kubectl get svc -n monitoring
          
          echo ""
          echo "=========================================="
          echo "=== SERVICEMONITOR STATUS ==="
          echo "=========================================="
          kubectl get servicemonitor -n app || echo "No ServiceMonitors found"
          
          echo ""
          echo "=========================================="
          echo "=== APPLICATION LOAD BALANCER IP ==="
          echo "=========================================="
          APP_IP=$(kubectl get svc sre-app-service -n app -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "pending")
          if [ "$APP_IP" != "pending" ]; then
            echo "Application URL: http://$APP_IP"
          else
            echo "LoadBalancer IP not yet assigned (this may take a few minutes)"
          fi
          
          echo ""
          echo "=========================================="
          echo "=== GRAFANA ACCESS ==="
          echo "=========================================="
          GRAFANA_IP=$(kubectl get svc monitoring-grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "pending")
          if [ "$GRAFANA_IP" != "pending" ]; then
            echo "Grafana URL: http://$GRAFANA_IP"
            echo "Username: admin"
            echo "Password: admin123"
          else
            echo "Grafana LoadBalancer IP pending..."
          fi
          
          echo ""
          echo "=========================================="
          echo "=== PROMETHEUS ACCESS ==="
          echo "=========================================="
          PROM_IP=$(kubectl get svc monitoring-kube-prometheus-prometheus -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "pending")
          if [ "$PROM_IP" != "pending" ]; then
            echo "Prometheus URL: http://$PROM_IP:9090"
          else
            echo "Prometheus LoadBalancer IP pending..."
          fi